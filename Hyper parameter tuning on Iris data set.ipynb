{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 18, 27, 36, 45, 54, 63, 72, 81, 90]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(int,np.linspace(10,90,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(iris.data,columns = iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame({'target':iris.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df_x,df_y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_x,df_y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_features = data_corr.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=[20,20])\n",
    "sns.heatmap(data[to_features].corr(),annot = True,cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression\n",
    "logistic_params = {'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                  'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "                  'C' : [100, 10, 1.0, 0.1, 0.01]}\n",
    "\n",
    "xgboost_params = {'learning_rate':[0.1,0.15,0.2,0.25,0.3],\n",
    "                 'max_depth' : [3,7,9,11,13,15],\n",
    "                 'min_child_weight':[1,3,5,7,9],\n",
    "                 'gamma':[0.1,0.2,0.25,0.3,0.4],\n",
    "                 'Colsample_bytree':[0.2,0.3,0.4,0.6,0.7]}\n",
    "\n",
    "dt_params = {'max_depth':list(map(int,np.linspace(1,32,32,endpoint=True))),\n",
    "            'min_samples_split':[0.2,0.3,0.5,0.6,0.7],\n",
    "            'min_samples_leaf':[0.2,0.3,0.4,0.5,0.6],\n",
    "            'max_features':['auto','sqrt'],\n",
    "            'criterion':['gini','entropy']}\n",
    "\n",
    "rf_params = {'n_estimators':list(map(int,np.linspace(10,90,10))),\n",
    "            'max_features':['auto','sqrt'],\n",
    "            'max_depth':list(map(int,np.linspace(1,10,10))),\n",
    "            'min_samples_split':[0.2,0.3,0.5,0.6,0.7],\n",
    "            'min_samples_leaf':[0.2,0.3,0.4,0.5,0.6]}\n",
    "\n",
    "gb_params = {'learning_rate' : [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "            'n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
    "            'max_depth':list(map(int,np.linspace(1,10,10))),\n",
    "           'min_samples_split':[0.2,0.3,0.5,0.6,0.7],\n",
    "           'min_samples_leaf':[0.2,0.3,0.4,0.5,0.6],\n",
    "            'max_features' : ['auto','sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = LogisticRegression()\n",
    "classifier2 = DecisionTreeClassifier()\n",
    "classifier3 = RandomForestClassifier()\n",
    "classifier4 = GradientBoostingClassifier()\n",
    "classifier5 = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "random1 = RandomizedSearchCV(classifier1,param_distributions=logistic_params,n_jobs = -1,cv = 5,verbose = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   27.2s finished\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "                   param_distributions={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                                        'penalty': ['none', 'l1', 'l2',\n",
       "                                                    'elasticnet'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='none')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "cross_score1 = cross_val_score(LogisticRegression(C=0.01, penalty='none'),x_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91666667, 1.        , 0.90909091, 1.        , 0.72727273,\n",
       "       0.81818182, 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': [0.9371212121212121]}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "score = {}\n",
    "score['LR']=[cross_score1.mean()]\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "cross_score_test1 = cross_val_score(LogisticRegression(C=0.01, penalty='none'),x_test,y_test,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['LR'].append(cross_score_test1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "random2 = RandomizedSearchCV(classifier2,param_distributions=dt_params,n_jobs = -1,cv = 5,verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [0.2, 0.3, 0.4, 0.5,\n",
       "                                                             0.6],\n",
       "                                        'min_samples_split': [0.2, 0.3, 0.5,\n",
       "                                                              0.6, 0.7]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, max_features='auto', min_samples_leaf=0.3,\n",
       "                       min_samples_split=0.5)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_score2 = cross_val_score(DecisionTreeClassifier(max_depth=2, max_features='auto', min_samples_leaf=0.3,\n",
    "                       min_samples_split=0.5),x_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score['DT'] = [cross_score2.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_score_test2 = cross_val_score(DecisionTreeClassifier(max_depth=2, max_features='auto', min_samples_leaf=0.3,\n",
    "                       min_samples_split=0.5),x_test,y_test,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['DT'].append(cross_score_test2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': [0.9371212121212121, 0.975],\n",
       " 'DT': [0.8643939393939393, 0.6583333333333334]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "random3 = RandomizedSearchCV(classifier3,param_distributions=rf_params,n_jobs = -1,cv = 5,verbose = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   17.3s finished\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [0.2, 0.3, 0.4, 0.5,\n",
       "                                                             0.6],\n",
       "                                        'min_samples_split': [0.2, 0.3, 0.5,\n",
       "                                                              0.6, 0.7],\n",
       "                                        'n_estimators': [10, 18, 27, 36, 45, 54,\n",
       "                                                         63, 72, 81, 90]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, max_features='sqrt', min_samples_leaf=0.3,\n",
       "                       min_samples_split=0.6, n_estimators=18)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "cross_score3 = cross_val_score(RandomForestClassifier(max_depth=3, max_features='sqrt', min_samples_leaf=0.3,\n",
    "                       min_samples_split=0.6, n_estimators=18),x_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['RF'] = [cross_score3.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "cross_score_test3 = cross_val_score(RandomForestClassifier(max_depth=3, max_features='sqrt', min_samples_leaf=0.3,\n",
    "                       min_samples_split=0.6, n_estimators=18),x_test,y_test,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['RF'].append(cross_score_test3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "random4 = RandomizedSearchCV(classifier5,param_distributions=xgboost_params,n_jobs = -1,cv = 5,verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.9s finished\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'Colsample_bytree': [0.2, 0.3, 0.4, 0.6,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.1, 0.2, 0.25, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.1, 0.15, 0.2, 0.25,\n",
       "                                                          0.3],\n",
       "                                        'max_depth': [3, 7, 9, 11, 13, 15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7, 9]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(Colsample_bytree=0.4, base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              gamma=0.4, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.25, max_delta_step=0,\n",
       "              max_depth=15, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "cross_score5 = cross_val_score(XGBClassifier(Colsample_bytree=0.4, base_score=0.5, booster='gbtree',\n",
    "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "              gamma=0.4, gpu_id=-1, importance_type='gain',\n",
    "              interaction_constraints='', learning_rate=0.25, max_delta_step=0,\n",
    "              max_depth=15, min_child_weight=3,\n",
    "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
    "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None),x_train,y_train,cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928030303030303"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_score5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Colsample_bytree } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "cross_score_test5 = cross_val_score(XGBClassifier(Colsample_bytree=0.4, base_score=0.5, booster='gbtree',\n",
    "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "              gamma=0.4, gpu_id=-1, importance_type='gain',\n",
    "              interaction_constraints='', learning_rate=0.25, max_delta_step=0,\n",
    "              max_depth=15, min_child_weight=3,\n",
    "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
    "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None),x_test,y_test,cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_score_test5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
